{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpRLMcINP/HDeTwVwOvnqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsendoinychko/Cp-decomposition/blob/main/res.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr18NEEkTsUj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Гіперпараметри\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 2\n",
        "\n",
        "# Завантаження та нормалізація набору даних CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Завантаження попередньо навченого VGG-16 і модифікація для 10 класів CIFAR-10\n",
        "class ModifiedVGG16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedVGG16, self).__init__()\n",
        "        self.vgg16 = torchvision.models.vgg16(pretrained=True)\n",
        "        self.vgg16.classifier[6] = nn.Linear(4096, 10)  # Змінюємо останній повнозв'язний шар на 10 виходів\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vgg16(x)\n",
        "        return x\n",
        "\n",
        "# Ініціалізація моделі, функції втрат та оптимізатора\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ModifiedVGG16()\n",
        "\n",
        "# Переводимо модель на декілька GPU, якщо доступні\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f'Using {torch.cuda.device_count()} GPUs!')\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Навчання моделі\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()  # Початок відліку часу\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Кожні 100 міні-батчів\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "    epoch_duration = time.time() - start_time  # Кінець відліку часу\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}] completed in {epoch_duration:.2f} seconds')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Тестування моделі\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Збереження моделі\n",
        "torch.save(model.state_dict(), 'vgg16_cifar10_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестування моделі\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Збереження моделі\n",
        "torch.save(model.state_dict(), 'vgg16_cifar10_model.pth')"
      ],
      "metadata": {
        "id": "XwTjDnxvTzlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "cum0rbzfU8_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if isinstance(model, nn.DataParallel):\n",
        "    model = model.module\n",
        "\n",
        "# Отримуємо третій згортковий шар\n",
        "conv_layer1 = model.vgg16.features[0]\n",
        "conv_layer2 = model.vgg16.features[2]\n",
        "conv_layer3 = model.vgg16.features[5]  # Індекс 4 відповідає третьому згортковому шару (починаючи з нуля)\n",
        "conv_layer4 = model.vgg16.features[7]\n",
        "conv_layer5 = model.vgg16.features[10]\n",
        "conv_layer6 = model.vgg16.features[12]\n",
        "conv_layer7 = model.vgg16.features[14]\n",
        "conv_layer8 = model.vgg16.features[17]\n",
        "conv_layer9 = model.vgg16.features[19]\n",
        "conv_layer10 = model.vgg16.features[21]\n",
        "conv_layer11 = model.vgg16.features[24]\n",
        "conv_layer12 = model.vgg16.features[26]\n",
        "conv_layer13 = model.vgg16.features[28]\n",
        "\n",
        "print(conv_layer7)"
      ],
      "metadata": {
        "id": "kNEj_oUSVDjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorly.decomposition import parafac\n",
        "from tensorly.decomposition import parafac\n",
        "import tensorly as tl\n",
        "\n",
        "def cp_decomposition_conv_layer(layer):\n",
        "    #device = layer.weight.device\n",
        "\n",
        "    tl.set_backend('pytorch')\n",
        "    S = layer.in_channels\n",
        "    T = layer.out_channels\n",
        "    rank = S*T/(S+T)\n",
        "    rank = round(rank)\n",
        "    print(rank)\n",
        "\n",
        "   # weights = layer.weight.data.to(device)\n",
        "    weights,(last, first, vertical, horizontal) = parafac(layer.weight.data, rank=rank, init='svd')\n",
        "\n",
        "    pointwise_s_to_r_layer = torch.nn.Conv2d(in_channels=first.shape[0], \\\n",
        "            out_channels=first.shape[1], kernel_size=1, stride=1, padding=0,\n",
        "            dilation=layer.dilation, bias=False)\n",
        "\n",
        "    depthwise_vertical_layer = torch.nn.Conv2d(in_channels=vertical.shape[1],\n",
        "            out_channels=vertical.shape[1], kernel_size=(vertical.shape[0], 1),\n",
        "            stride=1, padding=(layer.padding[0], 0), dilation=layer.dilation,\n",
        "            groups=vertical.shape[1], bias=False)\n",
        "\n",
        "    depthwise_horizontal_layer = \\\n",
        "        torch.nn.Conv2d(in_channels=horizontal.shape[1], \\\n",
        "            out_channels=horizontal.shape[1],\n",
        "            kernel_size=(1, horizontal.shape[0]), stride=layer.stride,\n",
        "            padding=(0, layer.padding[0]),\n",
        "            dilation=layer.dilation, groups=horizontal.shape[1], bias=False)\n",
        "\n",
        "    pointwise_r_to_t_layer = torch.nn.Conv2d(in_channels=last.shape[1], \\\n",
        "            out_channels=last.shape[0], kernel_size=1, stride=1,\n",
        "            padding=0, dilation=layer.dilation, bias=True)\n",
        "\n",
        "    pointwise_r_to_t_layer.bias.data = layer.bias.data\n",
        "\n",
        "    depthwise_horizontal_layer.weight.data = \\\n",
        "        torch.transpose(horizontal, 1, 0).unsqueeze(1).unsqueeze(1)\n",
        "    depthwise_vertical_layer.weight.data = \\\n",
        "        torch.transpose(vertical, 1, 0).unsqueeze(1).unsqueeze(-1)\n",
        "    pointwise_s_to_r_layer.weight.data = \\\n",
        "        torch.transpose(first, 1, 0).unsqueeze(-1).unsqueeze(-1)\n",
        "    pointwise_r_to_t_layer.weight.data = last.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "    new_layers = [pointwise_s_to_r_layer, depthwise_vertical_layer, \\\n",
        "                    depthwise_horizontal_layer, pointwise_r_to_t_layer]\n",
        "\n",
        "    return nn.Sequential(*new_layers)"
      ],
      "metadata": {
        "id": "Fjlt_CgXVDpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorly.decomposition import parafac\n",
        "tl.set_backend('pytorch')\n",
        "\n",
        "S = conv_layer5.in_channels\n",
        "T = conv_layer5.out_channels\n",
        "rank = S*T/(S+T)\n",
        "rank = round(rank)\n",
        "print(rank)\n",
        "\n",
        "   # weights = layer.weight.data.to(device)\n",
        "weights,(last, first, vertical, horizontal) = parafac(conv_layer5.weight.data, rank=rank, init='svd')"
      ],
      "metadata": {
        "id": "1S4yIj2CVDxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_layers5 = cp_decomposition_conv_layer(conv_layer5.cpu())\n",
        "new_layers6 = cp_decomposition_conv_layer(conv_layer6.cpu())\n",
        "new_layers7 = cp_decomposition_conv_layer(conv_layer7.cpu())\n",
        "new_layers8 = cp_decomposition_conv_layer(conv_layer8.cpu())"
      ],
      "metadata": {
        "id": "RmETsZsGVMyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.vgg16.features[5] = nn.Sequential(*new_layer3).cuda()"
      ],
      "metadata": {
        "id": "uIxbZQ65V5Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()  # Початок відліку часу\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Кожні 100 міні-батчів\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "    epoch_duration = time.time() - start_time  # Кінець відліку часу\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}] completed in {epoch_duration:.2f} seconds')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "t8iWFJu4V-fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестування моделі\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Збереження моделі\n",
        "torch.save(model.state_dict(), 'vgg16_cifar10_model.pth')"
      ],
      "metadata": {
        "id": "sBwrlVvJWBXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorly.decomposition import parafac\n",
        "import tensorly as tl\n",
        "\n",
        "# Визначення функції CP-декомпозиції\n",
        "def torch_cp_decomp(layer, rank):\n",
        "    W = layer.weight.data\n",
        "\n",
        "    weights,(last, first, vertical, horizontal) = parafac(W, rank=rank, init='random')\n",
        "\n",
        "\n",
        "    pointwise_s_to_r_layer = nn.Conv2d(in_channels=first.shape[0],\n",
        "                                       out_channels=first.shape[1],\n",
        "                                       kernel_size=1,\n",
        "                                       padding=0,\n",
        "                                       bias=False)\n",
        "\n",
        "    depthwise_r_to_r_layer = nn.Conv2d(in_channels=rank,\n",
        "                                       out_channels=rank,\n",
        "                                       kernel_size=vertical.shape[0],\n",
        "                                       stride=layer.stride,\n",
        "                                       padding=layer.padding,\n",
        "                                       dilation=layer.dilation,\n",
        "                                       groups=rank,\n",
        "                                       bias=False)\n",
        "\n",
        "    pointwise_r_to_t_layer = nn.Conv2d(in_channels=last.shape[1],\n",
        "                                       out_channels=last.shape[0],\n",
        "                                       kernel_size=1,\n",
        "                                       padding=0,\n",
        "                                       bias=True)\n",
        "\n",
        "    if layer.bias is not None:\n",
        "        pointwise_r_to_t_layer.bias.data = layer.bias.data\n",
        "\n",
        "    sr = first.t_().unsqueeze_(-1).unsqueeze_(-1)\n",
        "    rt = last.unsqueeze_(-1).unsqueeze_(-1)\n",
        "    rr = torch.stack([vertical.narrow(1, i, 1) @ torch.t(horizontal).narrow(0, i, 1) for i in range(rank)]).unsqueeze_(1)\n",
        "\n",
        "    pointwise_s_to_r_layer.weight.data = sr\n",
        "    pointwise_r_to_t_layer.weight.data = rt\n",
        "    depthwise_r_to_r_layer.weight.data = rr\n",
        "\n",
        "    new_layers = [pointwise_s_to_r_layer,\n",
        "                  depthwise_r_to_r_layer, pointwise_r_to_t_layer]\n",
        "    return new_layers"
      ],
      "metadata": {
        "id": "z0gXaD30WEK4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}